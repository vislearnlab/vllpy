{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vislearnlabpy.embeddings.generate_embeddings import EmbeddingGenerator\n",
    "from vislearnlabpy.embeddings.embedding_store import EmbeddingStore\n",
    "from vislearnlabpy.embeddings.utils import display_search_results, zscore_embeddings, filter_embeddings \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading CLIP embeddings\n",
    "First let's load our CLIP embedding generator. You can modify the device you're using here. By default this uses cpu or cuda:0 if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator = EmbeddingGenerator(model_type=\"clip\", device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: First, a simple example with just the embeddings from a directory of images saved within a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_generator.generate_image_embeddings(input_dir=\"input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see the output embeddings in the output subfolder! You'll also notice that our batch size is currently set to 1. By default, this is saved as a csv with embeddings listed. However, you can specify an output folder, the batch size etc. and save as a docarray or as numpy arrays. Update the values below to reflect in the rest of the file (after example 2). You can leave these as they are too for default behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these here to reflect in the rest of the file. You can leave these as they are for default behavior\n",
    "OUTPUT_DIRECTORY = None\n",
    "INPUT_CSV = None # for example '/ccn2/dataset/babyview/outputs_20250312/yoloe_cdi_100k_cropped_by_class/cropped_images_summary.csv'\n",
    "INPUT_DIRECTORY = None\n",
    "OVERWRITE = True\n",
    "BATCH_SIZE = 1000 # how many images are being processed in one go\n",
    "SAVE_EVERY_BATCH = False\n",
    "OUTPUT_TYPE = \"doc\" # options are \"doc\" for docarray, \"npy\" for numpys, \"csv\" for numbers in a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 2: Using a CSV file with image paths. To make full use of the pipeline, we recommend saving the embeddings using docarray. Both examples are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingGenerator(output_type=\"npy\").generate_image_embeddings(input_csv=\"input/inputs.csv\", overwrite=OVERWRITE, batch_size=BATCH_SIZE, save_every_batch=SAVE_EVERY_BATCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingGenerator(output_type=\"doc\").generate_image_embeddings(input_csv=\"input/inputs.csv\", overwrite=OVERWRITE, batch_size=BATCH_SIZE, save_every_batch=SAVE_EVERY_BATCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see both the npy csv and the docs file also in the output folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert a npy csv into an embedding store, which we'll be using to search through and filter through embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_store = EmbeddingStore.from_csv(\"output/image_embeddings/clip_image_embeddings_npy.csv\")\n",
    "embedding_store.EmbeddingList[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All you now! The rest of the examples below will reflect the store created below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if INPUT_DIRECTORY is None and INPUT_CSV is None:\n",
    "    INPUT_CSV = \"input/inputs.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EmbeddingGenerator(output_type=\"doc\").generate_image_embeddings(input_csv=INPUT_CSV, batch_size=BATCH_SIZE,\n",
    "                                                                output_path=OUTPUT_DIRECTORY, input_dir=INPUT_DIRECTORY,\n",
    "                                                                save_every_batch=SAVE_EVERY_BATCH, overwrite=OVERWRITE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a store from the created embedding docarray (you might have to change the path here depending on your parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_store = EmbeddingStore.from_doc(\"output/image_embeddings/clip_image_embeddings_doc.docs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching through embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, scores = embedding_store.search_store(text_query=\"spoon\", limit=10, categories=[\"spoon\"])\n",
    "display_search_results(docs, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize embeddings using z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_store.EmbeddingList.normed_embedding = zscore_embeddings(np.stack(embedding_store.EmbeddingList.embedding))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering images based on alignment with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_store = filter_embeddings(embedding_store, alignment_val=0.26)\n",
    "print(f\"Original file size: {len(embedding_store.EmbeddingList)}\")\n",
    "print(f\"New file size: {len(filtered_store.EmbeddingList)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vislearnlabpy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
